{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.6/site-packages/pydub/utils.py:178: RuntimeWarning: Couldn't find ffplay or avplay - defaulting to ffplay, but may not work\n",
      "  warn(\"Couldn't find ffplay or avplay - defaulting to ffplay, but may not work\", RuntimeWarning)\n",
      "/Users/apple/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "from scipy import signal\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from pydub.playback import play\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "# For CPU only\n",
    "#pip install tf-nightly  \n",
    "# For GPU support\n",
    "#pip install tf-nightly-gpu\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validata set 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"/Users/apple/Desktop/train/train/audio\"\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 1 - train_ratio\n",
    "\n",
    "classnames = os.listdir(train_path)\n",
    "if '_background_noise_' in classnames:\n",
    "    classnames.remove('_background_noise_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 화자별로 따로 나눌 new_train, val_train폴더 및 클래스 폴더 생성\n",
    "\n",
    "new_train_path = \"/Users/apple/Desktop/new_train\"\n",
    "val_train_path  = \"/Users/apple/Desktop/val_train\"\n",
    "\n",
    "os.mkdir(new_train_path)\n",
    "os.mkdir(val_train_path)\n",
    "\n",
    "for m in classnames:\n",
    "    target = os.path.join(new_train_path,m)\n",
    "    os.mkdir(target)\n",
    "    \n",
    "    target = os.path.join(val_train_path,m)\n",
    "    os.mkdir(target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "eight\n",
      "cat\n",
      "tree\n",
      "bed\n",
      "happy\n",
      "go\n",
      "dog\n",
      "no\n",
      "wow\n",
      "nine\n",
      "left\n",
      "stop\n",
      "three\n",
      "sheila\n",
      "one\n",
      "bird\n",
      "zero\n",
      "seven\n",
      "up\n",
      "marvin\n",
      "two\n",
      "house\n",
      "down\n",
      "six\n",
      "yes\n",
      "on\n",
      "five\n",
      "off\n",
      "four\n"
     ]
    }
   ],
   "source": [
    "for d in classnames:\n",
    "    print(d)\n",
    "    temp = os.listdir(os.path.join(train_path,d))\n",
    "    temp2 = [] \n",
    "\n",
    "    for i in temp:\n",
    "        temp2.append(i.split(\"_\")[0])  # 화자에 대한 정보\n",
    "\n",
    "    name_set = set(temp2) # unique\n",
    "\n",
    "    train_num = round(len(name_set) * train_ratio)\n",
    "    val_num = round(len(name_set) * val_ratio)\n",
    "    train_name = []\n",
    "    val_name = []\n",
    "\n",
    "    values = np.array(temp2)\n",
    "\n",
    "    for j in range(train_num):\n",
    "        searchval = values[j]\n",
    "        ii = np.where(values == searchval)[0]\n",
    "        train_name.append( [temp[x] for x in list(ii)] )\n",
    "        \n",
    "    train_name2 = [y for x in train_name for y in x] \n",
    "\n",
    "    for q in train_name2:\n",
    "        shutil.copy(src = os.path.join(train_path, d,q),  #파일 복사\n",
    "                   dst = os.path.join(new_train_path, d,q))\n",
    "\n",
    "\n",
    "    for k in range(val_num):\n",
    "        searchval = values[k]\n",
    "        ii = np.where(values == searchval)[0]\n",
    "        val_name.append( [temp[x] for x in list(ii)] )\n",
    "        \n",
    "    val_name2 = [y for x in val_name for y in x]\n",
    "        \n",
    "    for q in val_name2:\n",
    "        shutil.copy(src = os.path.join(train_path, d,q),  #파일 복사\n",
    "                    dst = os.path.join(val_train_path, d,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# noise 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noise_systhesis_path(audio_path, noise_path):    \n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    noise = AudioSegment.from_file(noise_path)    \n",
    "    combine = audio.overlay(noise)    \n",
    "    combine.export(audio_path, format=\"wav\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_audio = [\"/Users/apple/Desktop/train/train/audio/_background_noise_/doing_the_dishes.wav\",\n",
    "              \"/Users/apple/Desktop/train/train/audio/_background_noise_/dude_miaowing.wav\",\n",
    "              \"/Users/apple/Desktop/train/train/audio/_background_noise_/exercise_bike.wav\",\n",
    "              \"/Users/apple/Desktop/train/train/audio/_background_noise_/pink_noise.wav\",\n",
    "              \"/Users/apple/Desktop/train/train/audio/_background_noise_/running_tap.wav\",\n",
    "              \"/Users/apple/Desktop/train/train/audio/_background_noise_/white_noise.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "eight\n",
      "cat\n",
      "tree\n",
      "bed\n",
      "happy\n",
      "go\n",
      "dog\n",
      "no\n",
      "wow\n",
      "nine\n",
      "left\n",
      "stop\n",
      "three\n",
      "sheila\n",
      "one\n",
      "bird\n",
      "zero\n",
      "seven\n",
      "up\n",
      "marvin\n",
      "two\n",
      "house\n",
      "down\n",
      "six\n",
      "yes\n",
      "on\n",
      "five\n",
      "off\n",
      "four\n"
     ]
    }
   ],
   "source": [
    "for name in classnames:\n",
    "    print(name)\n",
    "    path = os.path.join(new_train_path,name)\n",
    "    audio_list = os.listdir(path)\n",
    "    \n",
    "    for audio in audio_list:\n",
    "        if random.random() <= 0.2:\n",
    "            noise_systhesis_path(os.path.join(path,audio),noise_audio[random.randrange(0,6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "eight\n",
      "cat\n",
      "tree\n",
      "bed\n",
      "happy\n",
      "go\n",
      "dog\n",
      "no\n",
      "wow\n",
      "nine\n",
      "left\n",
      "stop\n",
      "three\n",
      "sheila\n",
      "one\n",
      "bird\n",
      "zero\n",
      "seven\n",
      "up\n",
      "marvin\n",
      "two\n",
      "house\n",
      "down\n",
      "six\n",
      "yes\n",
      "on\n",
      "five\n",
      "off\n",
      "four\n"
     ]
    }
   ],
   "source": [
    "for name in classnames:\n",
    "    print(name)\n",
    "    path = os.path.join(val_train_path,name)\n",
    "    audio_list = os.listdir(path)\n",
    "    \n",
    "    for audio in audio_list:\n",
    "        if random.random() <= 0.2:\n",
    "            noise_systhesis_path(os.path.join(path,audio),noise_audio[random.randrange(0,6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, val, test 고화질 스펙트로그램 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이미지 담을 폴더 생성\n",
    "\n",
    "train_image_path = \"/Users/apple/Desktop/train_image\"\n",
    "val_image_path  = \"/Users/apple/Desktop/val_image\"\n",
    "\n",
    "os.mkdir(train_image_path)\n",
    "os.mkdir(val_image_path)\n",
    "\n",
    "for m in classnames:\n",
    "    target = os.path.join(train_image_path,m)\n",
    "    os.mkdir(target)\n",
    "    \n",
    "    target = os.path.join(val_image_path,m)\n",
    "    os.mkdir(target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image_path = \"/Users/apple/Desktop/test_image\"\n",
    "os.mkdir(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hz_to_mel(freq):\n",
    "    return 1127. * tf.log(1.0 + (freq / 700.))\n",
    "\n",
    "def mel_to_hz(mel):\n",
    "    return 700.*(tf.exp(mel/1127.)-1.)\n",
    "\n",
    "def multi_ffts_to_mel(freq_array, n_mels=128):\n",
    "    melfreq_array = tf.expand_dims(hz_to_mel(freq_array),0)\n",
    "  \n",
    "    mel_edges = tf.lin_space(hz_to_mel(tf.reduce_min(freq_array)), #or just use 0\n",
    "                           hz_to_mel(tf.reduce_max(freq_array)), #or SR/2\n",
    "                           n_mels+2)\n",
    "  \n",
    "    lower_edge_mel, center_mel, upper_edge_mel =tf.split(tf.contrib.signal.frame(mel_edges, 3, 1, axis=-1), 3, axis=-1)\n",
    "\n",
    "    wt_down = (melfreq_array - lower_edge_mel) / (center_mel - lower_edge_mel)\n",
    "    wt_up = (upper_edge_mel - melfreq_array) / (upper_edge_mel - center_mel)\n",
    "  \n",
    "    mel_weights_matrix = tf.maximum(0.0, tf.minimum(wt_down, wt_up))\n",
    "    center_mel_freqs = mel_to_hz(center_mel) \n",
    "  \n",
    "    return mel_weights_matrix, center_mel_freqs\n",
    "\n",
    "def audioframes2logmelspec(b_framed_signal, n_ffts=5, wvls_per_window_hinge=16, n_mel=128, fft_l1=1024, sr=16000):\n",
    "  # batch_framed_signal has shape: (batch_size x n_windows x fft_l1)\n",
    "  # decrease weights for samples w/ more than wvls_per_window_hinge\n",
    "  # wvls_per_window_hinge method could be improved, maybe weight~pmf of poisson?\n",
    "    \n",
    "    fft1_space = tf.lin_space(0., .5, 1+fft_l1//2)[1:]\n",
    "    freq_list =[sr*fft1_space] \n",
    "    n_wv_list =[fft_l1*fft1_space]\n",
    "\n",
    "    fft_list =[tf.spectral.rfft(b_framed_signal)[:,:,1:]]\n",
    "  \n",
    "    for i in range(1,n_ffts):\n",
    "        fft_lnew = fft_l1//2**i\n",
    "        fftnew_space = tf.lin_space(0., .5, 1+fft_lnew//2)[1:]\n",
    "    \n",
    "        freq_list.append(sr*fftnew_space)\n",
    "        n_wv_list.append(fft_lnew*fftnew_space)\n",
    "    \n",
    "        frames_new = b_framed_signal[:, :, (fft_l1-fft_lnew)//2:(fft_l1-fft_lnew)//2+fft_lnew]\n",
    "        fft_list.append(tf.spectral.rfft(frames_new)[:,:,1:])\n",
    "    \n",
    "  \n",
    "    freq_concat = tf.concat(freq_list, axis=-1)\n",
    "    n_wv_concat = tf.concat(n_wv_list, axis=-1)\n",
    "    fft_concat = tf.concat(fft_list, axis=-1)\n",
    "    \n",
    "    magnitude_spectros = tf.abs(fft_concat)\n",
    "\n",
    "    mel_wts, center_mel_freqs = multi_ffts_to_mel(freq_concat, n_mel)\n",
    "    wvls_wts = tf.where(n_wv_concat>wvls_per_window_hinge, wvls_per_window_hinge/n_wv_concat, tf.ones_like(n_wv_concat))\n",
    "  \n",
    "    mel_spectro=tf.tensordot(magnitude_spectros, (mel_wts*tf.expand_dims(wvls_wts,0)),axes = [[2], [1]])\n",
    "\n",
    "    log_mel_spectro = tf.log(mel_spectro+1e-7)\n",
    "  \n",
    "    return tf.expand_dims(log_mel_spectro, -1), center_mel_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_several_logmelspec(path,save_dir):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "    sr, y = wavfile.read(path)\n",
    "    signal = y.astype(np.float32) / np.iinfo(np.int16).max\n",
    "\n",
    "    b_signals = tf.expand_dims(signal, axis=0)\n",
    "\n",
    "    b_framed_signal = tf.contrib.signal.frame(b_signals, frame_length=1024, frame_step = 32)\n",
    "    log_mel_spectro, center_mel_freqs = audioframes2logmelspec(b_framed_signal, sr=sr)\n",
    "\n",
    "    librosa.display.specshow(log_mel_spectro[0,:,:,0].numpy().T, sr=sr, \n",
    "                             #x_axis='time', y_axis='mel', \n",
    "                             hop_length=32, \n",
    "                             fmin=tf.reduce_min(center_mel_freqs), \n",
    "                             fmax=tf.reduce_max(center_mel_freqs), \n",
    "                             cmap='coolwarm')\n",
    "\n",
    "    fig.savefig(save_dir, bbox_inches='tight', pad_inches=0)\n",
    "    #plt.tight_layout()\n",
    "    plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_path = \"/Users/apple/Desktop/new_train\"\n",
    "val_train_path  = \"/Users/apple/Desktop/val_train\"\n",
    "\n",
    "train_image_path = \"/Users/apple/Desktop/train_image\"\n",
    "val_image_path  = \"/Users/apple/Desktop/val_image\"\n",
    "test_image_path = \"/Users/apple/Desktop/test_image\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marvin\n",
      "two\n",
      "house\n",
      "down\n",
      "six\n",
      "yes\n",
      "on\n",
      "five\n",
      "off\n",
      "four\n"
     ]
    }
   ],
   "source": [
    "for name in classnames:\n",
    "    print(name)\n",
    "    path = os.path.join(new_train_path,name)\n",
    "    audio_list = os.listdir(path)\n",
    "    \n",
    "    for audio in audio_list:\n",
    "        audio_dir = os.path.join(path,audio)\n",
    "        save_dir = os.path.join(train_image_path,name,audio.split(\".\")[0]+\".png\")\n",
    "        \n",
    "        plot_several_logmelspec(audio_dir,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "eight\n",
      "cat\n",
      "tree\n",
      "bed\n",
      "happy\n",
      "go\n",
      "dog\n",
      "no\n",
      "wow\n",
      "nine\n",
      "left\n",
      "stop\n",
      "three\n",
      "sheila\n",
      "one\n",
      "bird\n",
      "zero\n",
      "seven\n",
      "up\n",
      "marvin\n",
      "two\n",
      "house\n",
      "down\n",
      "six\n",
      "yes\n",
      "on\n",
      "five\n",
      "off\n",
      "four\n"
     ]
    }
   ],
   "source": [
    "for name in classnames:\n",
    "    print(name)\n",
    "    path = os.path.join(val_train_path,name)\n",
    "    audio_list = os.listdir(path)\n",
    "    \n",
    "    for audio in audio_list:\n",
    "        audio_dir = os.path.join(path,audio)\n",
    "        save_dir = os.path.join(val_image_path,name,audio.split(\".\")[0]+\".png\")\n",
    "        \n",
    "        plot_several_logmelspec(audio_dir,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/apple/Desktop/test/test/audio\"\n",
    "audio_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for audio in audio_list[:10000]:\n",
    "    if index % 1000 == 0:\n",
    "        print(index)\n",
    "    index = index+1\n",
    "    \n",
    "    audio_dir = os.path.join(path,audio)\n",
    "    save_dir = os.path.join(test_image_path,audio.split(\".\")[0]+\".png\")\n",
    "        \n",
    "    plot_several_logmelspec(audio_dir,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
