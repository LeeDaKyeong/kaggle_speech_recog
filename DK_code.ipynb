{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import signal\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = 'yes no up down left right on off stop go silence unknown'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 웨이브 파일 로드, sr = 44100, 진폭 정규화까지\n",
    "def call_audio_librosa(path, sr = 44100):\n",
    "    y, sr = librosa.load(path,sr = sr)\n",
    "    y = audio_regul(y)\n",
    "    #y = audio_extract(y)\n",
    "    return (y, sr)\n",
    "\n",
    "# 음성 정규화\n",
    "def audio_regul(y):\n",
    "    _y = librosa.util.normalize(y)\n",
    "    return _y\n",
    "\n",
    "# librosa로 로드한거 인풋으로 넣었을 때\n",
    "def denoise(y):\n",
    "    D_noise = librosa.stft(y)\n",
    "    D_denoise = signal.wiener(D_noise)\n",
    "    y_denoised = librosa.istft(D_denoise)\n",
    "    return y_denoised\n",
    "\n",
    "# wav파일 path넣었을 때 바로 디노이징으로 불러오기\n",
    "def denoise_path(path):\n",
    "    y = call_audio_librosa(path)\n",
    "    D_noise = librosa.stft(y)\n",
    "    D_denoise = signal.wiener(D_noise)\n",
    "    y_denoised = librosa.istft(D_denoise)\n",
    "    return y_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_path = 'D:\\\\kaggle\\\\audio'\n",
    "os.listdir(main_path)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class 별 데이터 수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_path = 'D:\\\\kaggle\\\\audio'\n",
    "classnames=os.listdir(main_path)\n",
    "train_count_dict = {}\n",
    "temp = []\n",
    "for d in classnames:\n",
    "    people = os.listdir(os.path.join(main_path, d))\n",
    "    length = len(people)\n",
    "    temp.append(length)\n",
    "    train_count_dict[d] = sum(temp)\n",
    "train_count_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = 'D:\\\\kaggle\\\\train_image'\n",
    "for m in range(len(classnames)):\n",
    "    target = os.path.join(output_path,classnames[m])\n",
    "    os.mkdir(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_image 폴더를 만들고 word폴더를 만든 뒤, 이미지 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "input_path= 'D:\\\\kaggle\\\\train'\n",
    "output_path = 'D:\\\\kaggle\\\\train_image'\n",
    "    \n",
    "for word in classnames:\n",
    "    print(word)\n",
    "    word_path = os.path.join(input_path,word)\n",
    "    \n",
    "    for audio in os.listdir(word_path):\n",
    "        y, sr = librosa.load(os.path.join(word_path, audio), sr=16000)  #NOT 44100\n",
    "        #y = denoise(y)\n",
    "\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        MFCC = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        librosa.display.specshow(MFCC)\n",
    "\n",
    "        save_dir = output_path + \"\\\\\" + word + \"\\\\\" + audio.split(\".\")[0] + \".png\"\n",
    "        fig.savefig(save_dir, bbox_inches='tight', pad_inches=0)  # save the figure to file\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path= 'D:\\\\kaggle\\\\train'\n",
    "output_path = 'D:\\\\kaggle\\\\train_image'\n",
    "\n",
    "for word in classnames:\n",
    "    print(word)\n",
    "    word_path = os.path.join(input_path,word)\n",
    "    \n",
    "    for audio in os.listdir(word_path):\n",
    "        y, sr = librosa.load(os.path.join(word_path, audio), sr=16000)  #NOT 44100\n",
    "        MFCC = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        #S = librosa.feature.melspectrogram(S=D, n_mels=512)\n",
    "        \n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        #librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "        librosa.display.specshow(MFCC)\n",
    "        save_dir = output_path + \"\\\\\" + word + \"\\\\\" + audio.split(\".\")[0] + \".png\"\n",
    "        fig.savefig(save_dir, bbox_inches='tight', pad_inches=0)  # save the figure to file\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = 'D:\\\\kaggle\\\\test_image'\n",
    "for m in range(len(classnames)):\n",
    "    target = os.path.join(output_path,classnames[m])\n",
    "    os.mkdir(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path= 'D:\\\\kaggle\\\\test'\n",
    "output_path = 'D:\\\\kaggle\\\\test_image'\n",
    "    \n",
    "for word in classnames:\n",
    "    print(word)\n",
    "    word_path = os.path.join(input_path,word)\n",
    "    \n",
    "    for audio in os.listdir(word_path):\n",
    "        y, sr = librosa.load(os.path.join(word_path, audio), sr=16000)  #NOT 44100\n",
    "        #y = denoise(y)\n",
    "\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        MFCC = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        librosa.display.specshow(MFCC)\n",
    "\n",
    "        save_dir = output_path + \"\\\\\" + word + \"\\\\\" + audio.split(\".\")[0] + \".png\"\n",
    "        fig.savefig(save_dir, bbox_inches='tight', pad_inches=0)  # save the figure to file\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지를 train 과 test로 나누는 코드 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_path = 'D:\\\\kaggle\\\\audio'\n",
    "train_path = 'D:\\kaggle\\\\train_image'\n",
    "test_path = 'D:\\kaggle\\\\test_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(341, 224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical')\n",
    "# 65744개의 이미지를 20사이즈로 학습시키니 3287번은 학습해야 한 epoch가 완성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(341, 224),    \n",
    "        batch_size=30,\n",
    "        class_mode='categorical',\n",
    "shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=(3, 3), activation='elu',input_shape=(341,224,3),kernel_initializer= 'glorot_normal' ))\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), strides=1,activation='elu',kernel_initializer= 'glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='elu', strides=1,kernel_initializer= 'glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', strides=1,kernel_initializer= 'glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='elu',kernel_initializer= 'glorot_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='elu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model.add(Dense(len(train_generator.class_indices) , activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(8, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(341,224,3),kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model2.add(Conv2D(filters = 16, kernel_size = (5, 5), strides=1,activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model2.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model2.add(Conv2D(32, (5, 5), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model2.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model2.add(Conv2D(64, (5, 5), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model2.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(64, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model2.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(8, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(341,224,3),kernel_initializer= 'glorot_normal'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model3.add(Conv2D(filters = 16, kernel_size = (5, 5), strides=1,activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model3.add(Conv2D(32, (5, 5), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model3.add(Conv2D(64, (5, 5), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(64, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model3.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(8, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(341,224,3),kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model4.add(Conv2D(filters = 16, kernel_size = (5, 5), strides=1,activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model4.add(Conv2D(32, (5, 5), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model4.add(Conv2D(64, (5, 5), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model4.add(Conv2D(128, (5, 5), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(64, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model4.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(341,224,3),kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model5.add(Conv2D(filters = 16, kernel_size = (3, 3), strides=1,activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model5.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model5.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model5.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(128, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(64, activation='relu',kernel_initializer= 'glorot_normal'))\n",
    "\n",
    "model5.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=500, #30 이미지를 250번 학습시키는 것이 1 epoch로 정의.\n",
    "        epochs=100,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=25)#,\n",
    "        #callbacks=[early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist2 = model2.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=500, #20개 이미지를 300번 학습시키는 것이 1 epoch로 정의.\n",
    "        epochs=100,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=25)#,\n",
    "        #callbacks=[early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist3 = model3.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=500, #20개 이미지를 300번 학습시키는 것이 1 epoch로 정의.\n",
    "        epochs=100,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=25)#,\n",
    "        #callbacks=[early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist4 = model4.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=500, #20개 이미지를 300번 학습시키는 것이 1 epoch로 정의.\n",
    "        epochs=100,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=25)#,\n",
    "        #callbacks=[early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist5= model5.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=500, #20개 이미지를 300번 학습시키는 것이 1 epoch로 정의.\n",
    "        epochs=100,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=25)#,\n",
    "        #callbacks=[early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('CNN1_2.h5')\n",
    "model2.save('CNN2_2.h5')\n",
    "model3.save('CNN3_2.h5')\n",
    "model4.save('CNN4_2.h5')\n",
    "#model5.save('CNN5_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5.save('CNN5_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = load_model(\"CNN1.h5\")\n",
    "model2 = load_model(\"CNN2.h5\")\n",
    "model3 = load_model(\"CNN3.h5\")\n",
    "model4 = load_model(\"CNN4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_and_acc_plot(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_and_acc_plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_and_acc_plot(hist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_and_acc_plot(hist3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_and_acc_plot(hist4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_and_acc_plot(hist5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensemble(prob1,prob2,acc_list = [1,2] )\n",
    "def model_ensemble(*prob, acc_list):\n",
    "    prob_list = [p for p in prob]\n",
    "\n",
    "    idx_acc_list = {idx: acc for idx, acc in enumerate(acc_list)}\n",
    "    sorted_acc_list = [idx for idx, _ in sorted(idx_acc_list.items(),\n",
    "                                                key=lambda value: (value[1], value[0]), reverse=True)]\n",
    "    output = []\n",
    "    for i in sorted_acc_list:\n",
    "        temp = [round(x * (i + 1), 5) for x in prob_list[i]]\n",
    "        output.append(temp)\n",
    "    final_prob = np.sum(output, axis=0)  # class갯수만큼 확률값 지금은 1*2\n",
    "\n",
    "    final_score = np.mean(np.equal(np.argmax(final_prob, axis=1), test_generator.classes))\n",
    "    print('Final val accuracy : %4f' % final_score)\n",
    "\n",
    "    return final_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path= 'D:\\\\kaggle\\\\test_set'\n",
    "output_path = 'D:\\\\kaggle\\\\test_image_kaggle\\\\test_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = 'D:\\\\kaggle\\\\test_image_kaggle\\\\temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for audio in os.listdir(input_path):\n",
    "    y, sr = librosa.load(os.path.join(input_path, audio), sr=16000)  #NOT 44100\n",
    "        #y = denoise(y)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    MFCC = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    librosa.display.specshow(MFCC)\n",
    "\n",
    "    save_dir = output_path + \"\\\\\" +  audio.split(\".\")[0] + \".png\"\n",
    "    fig.savefig(save_dir, bbox_inches='tight', pad_inches=0)  # save the figure to file\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = 'D:\\\\kaggle\\\\test_image_kaggle\\\\test_image'\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(341, 224),    \n",
    "        batch_size=100,\n",
    "        class_mode='categorical',\n",
    "shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob1 = model1.predict_generator(test_generator)\n",
    "prob2 = model2.predict_generator(test_generator)\n",
    "prob3 = model3.predict_generator(test_generator)\n",
    "prob4 = model4.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob = prob1+prob2+prob3+prob4\n",
    "result = np.argmax(prob, axis=1)\n",
    "\n",
    "result = np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech = {0: \"unknown\",\n",
    "          1: \"unknown\",\n",
    "          2: \"unknown\",\n",
    "          3: \"unknown\",\n",
    "          4: \"down\",\n",
    "          5: \"unknown\",\n",
    "          6: \"unknown\",\n",
    "          7: \"unknown\",\n",
    "          8: \"go\",\n",
    "          9: \"unknown\",\n",
    "          10: \"unknown\",\n",
    "          11: \"left\",\n",
    "         12:\"unknown\",\n",
    "         13:\"unknown\",\n",
    "         14:\"no\",\n",
    "         15:\"off\",\n",
    "         16:\"on\",\n",
    "         17:\"unknown\",\n",
    "         18:\"right\",\n",
    "         19:\"unknown\",\n",
    "         20:\"unknown\",\n",
    "         21:\"unknown\",\n",
    "         22:\"stop\",\n",
    "         23:\"unknown\",\n",
    "         24:\"unknown\",\n",
    "         25:\"unknown\",\n",
    "         26:\"up\",\n",
    "         27:\"unknown\",\n",
    "         28:\"yes\",\n",
    "         29:\"unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv    \n",
    "f = open('output.csv', 'w', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow([\"fname\",\"label\"])\n",
    "\n",
    "for i in range(len(result)): \n",
    "#for i in range(10): \n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    filename = test_generator.filenames[i].split(\"/\")[1].split(\".\")[0]+\".wav\"\n",
    "    path = os.path.join('D:\\\\kaggle\\\\test_set',filename)\n",
    "    y, sr = librosa.load(path,sr = 16000)\n",
    "    if sum(y) == 0:\n",
    "        wr.writerow([filename, \"silence\"])\n",
    "    else:\n",
    "        wr.writerow([filename, speech[result[i]]])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
